# Estructuras lineales (linear data structures)

---

## 1. Arrays y listas (arrays & lists)

### 1.1 Idea intuitiva

Un **array** (arreglo o vector) es una colección de elementos almacenados en posiciones **contiguas** de memoria, accesibles mediante un **índice entero**. Piénsalo como una fila de casillas numeradas consecutivamente (como columnas en Excel): cada casilla tiene un número (índice) y un valor.

Sirve para almacenar conjuntos de datos **homogéneos** (mismo tipo) de **tamaño fijo**, permitiendo acceder muy rápido a cualquier elemento sabiendo su posición.

Ejemplo: un array de tamaño `N` con índices de `0` a `N-1`. El elemento de la posición `5` se obtiene directamente, sin recorrer nada: acceso en tiempo constante (time complexity $O(1)$).

Problema: en muchos lenguajes el tamaño es **fijo** una vez creado. Si te quedas corto, hay que crear un array nuevo más grande y copiar.

Para aliviar esto aparecen las **listas dinámicas** o **arrays dinámicos** (_dynamic arrays_), que son estructuras que por dentro usan un array, pero que se **redimensiona automáticamente** cuando hace falta (por ejemplo, `ArrayList` en Java, `list` en Python, `std::vector` en C++). Al llegar a la capacidad máxima:

1. Crean un array más grande (típicamente el doble).
    
2. Copian los elementos antiguos.
    
3. Siguen trabajando como si nada.
    

Tú ves algo “elástico”; por debajo es un array que de vez en cuando se “muda de casa”.

---

### 1.2 Definición formal y propiedades

Un **array** de tamaño $N$:

- Estructura lineal de longitud fija con elementos indexados $0, 1, ..., N-1$.
    
- Todos del mismo tipo y almacenados en memoria contigua.
    
- Se puede ver como una función:  
    $A : {0, 1, ..., N-1} -> D$,  
    donde $D$ es el dominio de los valores (enteros, chars, etc.).
    

Propiedades clave:

- **Acceso aleatorio directo (random access)**  
    Dado un índice $i$, acceder a $A[i]$ es tiempo $O(1)$ (constante), porque físicamente se calcula algo del estilo:  
    `addr(A[i]) = addr(A[0]) + i * sizeof(tipo)`.
    
- **Tamaño fijo**  
    En Java/C/C++ estáticos, el tamaño se fija al crear el array. Para crecer más allá: crear uno nuevo y copiar todos los elementos (coste $O(N)$).
    
- **Almacenamiento contiguo**  
    Los elementos están uno detrás de otro en memoria. Esto:
    
    - Favorece la **localidad de referencia** (cache friendly).
        
    - Obliga a copiar si necesitas más espacio contiguo.
        

Una **lista dinámica** (array dinámico tipo `ArrayList`) es un **TAD Lista** con tamaño lógico variable. Internamente mantiene:

- Un array `data` de longitud `capacity`.
    
- Un entero `size` con el número real de elementos.
    

Cuando `size == capacity` y haces `add`:

1. Se crea un array nuevo, por ejemplo de capacidad `2 * capacity`.
    
2. Se copian los `size` elementos.
    
3. Se sustituye el array viejo por el nuevo.
    

Gracias a esa expansión geométrica, las inserciones al final tienen coste **amortizado** $O(1)$:

- Muchas inserciones muy baratas.
    
- Pocas inserciones caras (cuando toca copiar).
    

Operaciones típicas y coste (arrays / listas secuenciales):

- Acceso por índice: `A[i]` → tiempo $O(1)$.
    
- Búsqueda por valor (búsqueda lineal / _linear search_):  
    Peor caso: recorrer todos los elementos → tiempo $O(N)$.
    
- Inserción/eliminación al final:
    
    - En array estático con hueco: $O(1)$.
        
    - En array dinámico: $O(1)$ amortizado (a veces un `resize` de coste $O(N)$).
        
- Inserción/eliminación en posición arbitraria (inicio/medio):  
    Hay que desplazar elementos → coste $O(N)$.
    
- Memoria:
    
    - Array fijo: justo espacio para $N$ elementos → $O(N)$.
        
    - Array dinámico: algo de espacio extra (capacidad > tamaño), pero sigue siendo $O(N)$.
        

Conclusión rápida:

- Array: brutal si conoces tamaño y necesitas **acceso indexado rápido**.
    
- Lista dinámica: sacrifica algo de control por **flexibilidad de tamaño** con coste amortizado muy bueno.
    

---

### 1.3 Ejemplos en Java

**Array básico en Java:**

```Java
int[] numeros = new int[5];         // array de 5 enteros (inicializados a 0)
numeros[0] = 42;
numeros[1] = 13;

System.out.println(numeros[0]);    // Acceso directo: imprime 42

int idx = 1;
System.out.println(numeros[idx]);  // Imprime 13 (acceso usando variable índice)
```


Si intentas `numeros[5]` → `ArrayIndexOutOfBoundsException` (índice fuera de rango, porque el último índice válido es `4`).

**Lista dinámica con `ArrayList`:**

```Java
import java.util.ArrayList;

ArrayList<String> listaNombres = new ArrayList<>();

listaNombres.add("Ana");
listaNombres.add("Juan");
listaNombres.add("Luis");

System.out.println(listaNombres.get(1));   // Imprime "Juan"

listaNombres.remove(0);                    // Elimina "Ana", reacomoda la lista

System.out.println(listaNombres);          // Imprime [Juan, Luis]
```


`ArrayList` se encarga de:

- Redimensionar cuando hace falta.
    
- Mover elementos al hacer `remove` en el medio.
    

**Casos borde / errores típicos:**

- Acceder a índice fuera de rango.
    
- Confundir longitud $N$ con último índice $N-1$.
    
- Pensar que `ArrayList.remove(0)` es barato siempre: en realidad es $O(N)$ por desplazamientos.
    

---

### 1.4 Complejidad

**Array fijo:**

- Acceso `A[i]`:
    
    - Mejor/promedio/peor: tiempo $O(1)$.
        
- Búsqueda lineal:
    
    - Peor caso (no está o está al final): tiempo $O(N)$.
        
- Insertar/eliminar al final:
    
    - Si hay espacio: $O(1)$.
        
    - Si no hay espacio y quieres crecer: crear otro array y copiar → $O(N)$.
        
- Insertar/eliminar en posición $k$:
    
    - Hay que desplazar hasta $N - k$ elementos → $O(N)$.
        
- Espacio: $O(N)$.
    

**Array dinámico (tipo `ArrayList`):**

- Acceso por índice: tiempo $O(1)$.
    
- `add` al final:
    
    - Casi siempre $O(1)$.
        
    - A veces $O(N)$ por `resize`, pero **amortizado** → $O(1)$.
        
- Insertar/eliminar en medio:
    
    - Desplazar elementos → $O(N)$.
        
- Espacio:
    
    - `capacity` un poco mayor que `size`, pero sigue $O(N)$.
        

**Localidad de caché:**

- Arrays y array-lists son mucho más **cache-friendly** que estructuras enlazadas, porque los datos están contiguos.
    

---

### 1.5 Mini resumen (chuleta mental)

- **Array**:
    
    - Índices $0..N-1$, memoria contigua, acceso $O(1)$.
        
    - Insertar/quitar en medio → $O(N)$.
        
    - Tamaño fijo.
        
- **Array dinámico / lista dinámica** (por ejemplo `ArrayList`):
    
    - Internamente: array con `capacity` y `size`.
        
    - Al llenarse, se redimensiona (duplicando, típicamente).
        
    - `add` al final: $O(1)$ amortizado.
        
    - Quitar/insertar en medio: $O(N)$.
        
- **Cuándo usar**:
    
    - Usa **array / ArrayList** cuando necesites **acceso por índice rápido** y no estés todo el rato insertando en el medio.
        
    - Si vas a meter/quitar en medio constantemente, mejor mirar **listas enlazadas**.
        
- **Errores típicos de examen**:
    
    - Confundir $N$ con el último índice ($N-1$).
        
    - No contar el coste de desplazar elementos (asumir que `ArrayList.remove(0)` es $O(1)$).
        
    - Olvidar que el `resize` tiene coste $O(N)$ aunque amortizado.
        

---

## 2. Listas enlazadas (singly / doubly / circular linked lists)

### 2.1 Idea intuitiva

Una **lista enlazada (linked list)** es una estructura **dinámica** en la que cada elemento se guarda en un **nodo** que contiene:

- Un **valor** (`data`).
    
- Uno o más **punteros/enlaces** (`links`) a otros nodos.
    

No están en memoria contigua. Cada nodo “sabe” quién viene después (y en las dobles, quién viene antes).

Analogías:

- Una cadena de eslabones: cada eslabón apunta al siguiente.
    
- Una gymkhana con pistas: cada pista te dice dónde está la siguiente.
    

Ventajas:

- Insertar/eliminar elementos en medio es **muy barato** si ya estás en el sitio correcto: solo re-enlazar punteros.
    
- El tamaño es dinámico: crece/disminuye sin tener que copiar todo.
    

Desventajas:

- No hay **acceso aleatorio**: para llegar al elemento número $i$ hay que caminar desde el principio → $O(n)$.
    
- Peor localidad de caché: cada nodo puede estar en otra zona de memoria.
    

Variantes típicas:

- **Singly linked list** (simplemente enlazada): cada nodo tiene `next`.
    
- **Doubly linked list** (doblemente enlazada): cada nodo tiene `prev` y `next`.
    
- **Circular linked list**: el último nodo apunta al primero (y a veces el primero al último), formando un ciclo.
    

---

### 2.2 Definición formal y variantes

**Lista simplemente enlazada (singly linked list):**

- Conjunto de nodos $n_1, n_2, ..., n_k$.
    
- Cada nodo tiene:
    
    - `data`.
        
    - `next` apuntando al siguiente nodo (excepto el último, que apunta a `null`).
        
- Puntero externo `head` apunta al primer nodo $n_1$.
    
- Lista vacía: `head == null`.
    

Operaciones típicas:

- Insertar al inicio (`push_front`):  
    Nuevo nodo apunta a `head` y actualizamos `head`.  
    Coste: $O(1)$.
    
- Eliminar al inicio (`pop_front`):  
    `head = head.next`.  
    Coste: $O(1)$.
    
- Buscar por valor:  
    Recorrer hasta encontrarlo.  
    Peor caso: $O(n)$.
    
- Insertar después de un nodo conocido:
    
    - Coste $O(1)$ si ya tienes la referencia al nodo.
        
- Eliminar después de un nodo conocido:
    
    - Coste $O(1)$ si tienes la referencia al nodo anterior.
        

**Lista doblemente enlazada (doubly linked list):**

- Cada nodo tiene:
    
    - `data`.
        
    - `next` (siguiente).
        
    - `prev` (anterior).
        
- Sueles mantener punteros `head` y `tail`.
    
- Ventaja: si tienes referencia al nodo a eliminar, puedes quitarlo en $O(1)$ sin buscar el anterior:
    
    - Ajustas `prev.next` y `next.prev`.
        

Formalmente, si la lista tiene nodos $n_1, ..., n_k$:

- $n_1.prev = null$
    
- $n_k.next = null$
    
- Para $1 < i < k$:
    
    - $n_i.prev = n_{i-1}$
        
    - $n_i.next = n_{i+1}$
        

**Lista circular (circular linked list):**

- Último nodo no apunta a `null` sino de vuelta al primero.
    
- Puede ser simple o doblemente enlazada.
    
- En una circular doble con nodos $n_1, ..., n_k$:
    
    - $n_1.prev = n_k$
        
    - $n_k.next = n_1$
        
- No hay `null` al final; hay que definir condición de parada (por ejemplo, al volver al nodo origen).
    
- Útil en estructuras cíclicas (round-robin, buffers circulares, etc.).
    

Propiedades generales:

- Tamaño dinámico, se reserva nodo a nodo.
    
- Inserciones/eliminaciones locales (una vez estás en el sitio): $O(1)$.
    
- Búsqueda/acceso posicional: $O(n)$.
    
- Memoria extra por punteros en cada nodo.
    

---

### 2.3 Ejemplos y código en Java

**Nodo de lista simplemente enlazada:**

```Java
class Node {
    int data;
    Node next;

    Node(int data) {
        this.data = data;
        this.next = null;
    }
}
```


**Construir manualmente una lista `[10 -> 20 -> 30]`:**

```Java
Node head = new Node(10);       // primer nodo
head.next = new Node(20);       // segundo nodo
head.next.next = new Node(30);  // tercer nodo
```


**Recorrer e imprimir:**

```Java
Node current = head;
while (current != null) {
    System.out.println(current.data);
    current = current.next;
}
```


Salida:

```
10
20
30
```


**Insertar al inicio (`push_front`) valor `5`:**

```Java
Node newNode = new Node(5);
newNode.next = head;   // el nuevo nodo apunta al antiguo primero
head = newNode;        // head ahora es el nuevo nodo
```


Lista resultante: `[5 -> 10 -> 20 -> 30]`.

**Eliminar el primer nodo (`pop_front`):**

```Java
if (head != null) {
    head = head.next;
}
```


**Insertar `15` después del nodo con valor `10`:**

```Java
Node current = head;

// Buscar el nodo con data == 10
while (current != null && current.data != 10) {
    current = current.next;
}

if (current != null) {
    Node newNode = new Node(15);
    newNode.next = current.next;
    current.next = newNode;
}
```

Lista: `[5 -> 10 -> 15 -> 20 -> 30]`.

---

**Lista doblemente enlazada:**

```Java
class DNode {
    int data;
    DNode prev;
    DNode next;

    DNode(int d) {
        data = d;
        prev = next = null;
    }
}
```


**Insertar al final usando `tail`:**

```Java
DNode head = null;
DNode tail = null;

void addLast(int value) {
    DNode newNode = new DNode(value);
    if (tail == null) { // lista vacía
        head = tail = newNode;
    } else {
        tail.next = newNode;
        newNode.prev = tail;
        tail = newNode;
    }
}
```


**Eliminar un nodo `node` de una lista doblemente enlazada:**

```Java
void removeNode(DNode node) {
    if (node == null) return;

    if (node.prev != null) {
        node.prev.next = node.next;
    } else {
        head = node.next;   // node era la cabeza
    }

    if (node.next != null) {
        node.next.prev = node.prev;
    } else {
        tail = node.prev;   // node era la cola
    }
}
```


---

**Usar `LinkedList` de Java:**

```Java
import java.util.LinkedList;

LinkedList<String> listaEnlazada = new LinkedList<>();

listaEnlazada.add("A");        // inserta al final
listaEnlazada.addFirst("B");   // inserta al inicio
listaEnlazada.addLast("C");    // inserta al final

System.out.println(listaEnlazada); // [B, A, C]

listaEnlazada.remove("A");     // elimina la primera aparición de "A"

System.out.println(listaEnlazada); // [B, C]
```


---

**Casos borde / errores típicos:**

- Perder nodos al re-enlazar mal:
    
    - Por ejemplo, al eliminar un nodo intermedio, no relinkear correctamente y “cortar” el resto de la lista.
        
- No actualizar `prev` en listas dobles → estructura inconsistente.
    
- Olvidar actualizar `head`/`tail` al insertar/eliminar en extremos.
    
- En listas circulares, escribir bucles sin condición de parada adecuada → bucles infinitos.
    

---

### 2.4 Complejidad

Para una lista enlazada (singly o doubly):

- Insertar al inicio: $O(1)$.
    
- Eliminar al inicio: $O(1)$.
    
- Insertar al final:
    
    - Sin puntero `tail`: necesitas recorrer hasta el final → $O(n)$.
        
    - Con `tail`: $O(1)$.
        
- Eliminar al final:
    
    - Lista simple: si no tienes el anterior, hay que recorrer → $O(n)$.
        
    - Lista doble con `tail`: puedes eliminar `tail` en $O(1)$.
        
- Insertar/eliminar **después de un nodo conocido**: $O(1)$.
    
- Búsqueda por valor / acceso al nodo $i$:
    
    - Hay que recorrer desde `head` → $O(n)$.
        
- Espacio:
    
    - $O(n)$, pero con overhead de 1 o 2 punteros por nodo.
        
    - Menor localidad de caché que arrays.
        

Clave mental: listas enlazadas optimizan **inserciones/eliminaciones locales** y penalizan **acceso por índice**.

---

### 2.5 Mini resumen (chuleta mental)

- **Linked list**:
    
    - Nodos con `data` + punteros.
        
    - No hay memoria contigua, tamaño dinámico.
        
    - Insertar/eliminar en posiciones conocidas → $O(1)$.
        
    - Acceder al elemento $i$ → $O(n)$.
        
- **Singly linked list**:
    
    - Solo `next`.
        
    - Menos memoria, más sencilla.
        
    - Para eliminar un nodo necesitas referencia al anterior (o buscarlo).
        
- **Doubly linked list**:
    
    - `prev` y `next`.
        
    - Más memoria, pero eliminar un nodo dado es $O(1)$ sin buscar el anterior.
        
    - Más fácil recorrer hacia atrás.
        
- **Circular linked list**:
    
    - Último nodo apunta al primero.
        
    - Útil en rondas cíclicas, buffers circulares.
        
    - Cuidado con bucles infinitos.
        
- **Comparación rápida array vs lista enlazada**:
    
    - Array: acceso por índice $O(1)$, inserciones en medio $O(n)$.
        
    - Lista enlazada: acceso por índice $O(n)$, inserciones locales $O(1)$.
        
- **Errores de examen típicos**:
    
    - Dibujar mal la lista después de una inserción/eliminación.
        
    - Olvidar actualizar `head`/`tail`.
        
    - Olvidar alguno de los punteros en listas dobles (`prev` o `next`).
        

---

## 3. Pilas (stacks)

### 3.1 Idea intuitiva

Una **pila (stack)** es una estructura con disciplina **LIFO (Last In, First Out)**:

> El último en entrar es el primero en salir.

Analogía: una pila de platos. Pones platos uno encima de otro:

- Para poner un plato: lo dejas encima → operación `push`.
    
- Para coger un plato: coges el de arriba → operación `pop`.
    

No puedes sacar directamente el plato del centro sin quitar los de arriba. Lo mismo con una pila de datos: solo accedes al **tope (top)**.

Usos clásicos:

- **Call stack** o pila de llamadas de un programa (funciones recursivas).
    
- **Deshacer (undo)**: cada operación se apila, deshaces sacando la última.
    
- **Evaluación de expresiones** (notación postfija, etc.).
    
- **Backtracking** y **DFS (depth-first search)**.
    

---

### 3.2 Definición formal

TAD **Stack** (pila):

- `push(x)`: mete `x` en la cima.
    
- `pop()`: saca y devuelve el elemento de la cima.
    
- `peek()` o `top()`: devuelve el elemento de la cima sin sacarlo.
    
- `isEmpty()`, `size()`, etc.
    

Propiedad central: **LIFO**.

Errores clásicos:

- **Underflow**: hacer `pop` en pila vacía.
    
- **Overflow**: intentar `push` en pila llena (si es de capacidad fija).
    

Implementaciones típicas:

- Con **array**:
    
    - Array + índice `topIndex`.
        
- Con **linked list**:
    
    - Usando la cabeza de la lista como tope.
        

En ambos casos las operaciones son tiempo $O(1)$.

---

### 3.3 Ejemplos en Java

#### 3.3.1 Pila con array

```Java
class IntStack {
    private int[] stackArr;
    private int topIndex;

    public IntStack(int capacity) {
        stackArr = new int[capacity];
        topIndex = -1;  // pila vacía
    }

    public void push(int value) throws Exception {
        if (topIndex == stackArr.length - 1) {
            throw new Exception("Stack overflow");
        }
        stackArr[++topIndex] = value;
    }

    public int pop() throws Exception {
        if (topIndex < 0) {
            throw new Exception("Stack underflow");
        }
        int val = stackArr[topIndex--];
        return val;
    }

    public int peek() throws Exception {
        if (topIndex < 0) {
            throw new Exception("Stack underflow");
        }
        return stackArr[topIndex];
    }

    public boolean isEmpty() {
        return topIndex == -1;
    }
}
```


**Uso:**

```Java
IntStack stack = new IntStack(5);

stack.push(10);
stack.push(20);

System.out.println(stack.peek());  // 20

int x = stack.pop();
System.out.println(x);            // 20

System.out.println(stack.pop());  // 10
System.out.println(stack.isEmpty()); // true
```


#### 3.3.2 Pila con lista enlazada

Reutilizando `Node`:

```Java
class LinkedStack {
    private Node top;  // tope de la pila

    public LinkedStack() {
        top = null;
    }

    public void push(int val) {
        Node newNode = new Node(val);
        newNode.next = top;
        top = newNode;
    }

    public int pop() throws Exception {
        if (top == null) {
            throw new Exception("Stack underflow");
        }
        int val = top.data;
        top = top.next;
        return val;
    }

    public int peek() throws Exception {
        if (top == null) {
            throw new Exception("Stack underflow");
        }
        return top.data;
    }

    public boolean isEmpty() {
        return (top == null);
    }
}
```


#### 3.3.3 Usando `ArrayDeque` de Java

```Java
import java.util.ArrayDeque;
import java.util.Deque;

Deque<String> stack = new ArrayDeque<>();

stack.push("uno");
stack.push("dos");

System.out.println(stack.peek());  // "dos"
System.out.println(stack.pop());   // "dos"
System.out.println(stack.pop());   // "uno"
System.out.println(stack.isEmpty()); // true
```


---

### 3.4 Complejidad

Para una pila bien implementada:

- `push`: $O(1)$ (amortizado si array dinámico).
    
- `pop`: $O(1)$.
    
- `peek`: $O(1)$.
    
- `isEmpty`, `size`: $O(1)$.
    

No hay diferencia entre mejor/peor/promedio (salvo el caso puntual de `resize` en arrays dinámicos, que se considera amortizado).

Espacio:

- $O(n)$ para $n$ elementos.
    
- Muy poco overhead extra.
    

---

### 3.5 Mini resumen (chuleta mental)

- **Stack = LIFO**:
    
    - Último en entrar, primero en salir.
        
    - Solo el tope es visible.
        
- **Operaciones**:
    
    - `push`, `pop`, `peek`, `isEmpty`.
        
    - Todas $O(1)$.
        
- **Implementación**:
    
    - Array + índice `topIndex`.
        
    - Lista enlazada (insertar/eliminar en cabeza).
        
- **Errores típicos**:
    
    - `pop` o `peek` sobre pila vacía (underflow).
        
    - Pila recursiva infinita → `StackOverflowError`.
        
- **Usos típicos**:
    
    - Pila de llamadas.
        
    - DFS (recursivo/iterativo).
        
    - Evaluación de expresiones.
        
    - Sistemas de undo/redo.
        

---

## 4. Colas (queues)

### 4.1 Idea intuitiva

Una **cola (queue)** sigue disciplina **FIFO (First In, First Out)**:

> El primero en entrar es el primero en salir.

Analogía: cola en el súper. La gente se pone al final, y se atiende primero a quien lleva más tiempo esperando.

Propiedades:

- **Enqueue**: insertas al **final** de la cola.
    
- **Dequeue**: sacas del **frente** de la cola.
    
- FIFO: se respeta el orden de llegada.
    

Usos típicos:

- Sistemas de colas de impresión.
    
- Planificación de procesos (ready queue).
    
- Algoritmo **BFS (breadth-first search)** en grafos.
    
- Problemas productor-consumidor (buffers).
    

---

### 4.2 Definición formal

TAD **Queue**:

- `enqueue(x)` / `offer(x)`: añade `x` al final.
    
- `dequeue()` / `remove()` / `poll()`: saca y devuelve el elemento del frente.
    
- `peek()` / `front()`: devuelve el elemento del frente sin sacarlo.
    
- `isEmpty()`, `size()`, etc.
    

Tiene dos extremos:

- **Front (head)**: de donde salen elementos.
    
- **Rear (tail)**: donde entran.
    

Implementaciones típicas:

- Con **lista enlazada**:
    
    - `head` (front) y `tail` (rear).
        
- Con **array circular**:
    
    - Array + índices `headIndex` y `tailIndex` + `size`.
        

---

### 4.3 Ejemplo: cola circular con array en Java

```Java
class CircularQueue {
    private int[] arr;
    private int capacity;
    private int head;
    private int tail;
    private int currentSize;

    public CircularQueue(int N) {
        capacity = N;
        arr = new int[N];
        head = 0;
        tail = 0;
        currentSize = 0;
    }

    public void enqueue(int value) throws Exception {
        if (currentSize == capacity) {
            throw new Exception("Queue overflow (full)");
        }
        arr[tail] = value;
        tail = (tail + 1) % capacity;
        currentSize++;
    }

    public int dequeue() throws Exception {
        if (currentSize == 0) {
            throw new Exception("Queue underflow (empty)");
        }
        int value = arr[head];
        head = (head + 1) % capacity;
        currentSize--;
        return value;
    }

    public int peek() throws Exception {
        if (currentSize == 0) {
            throw new Exception("Empty queue");
        }
        return arr[head];
    }

    public boolean isEmpty() {
        return currentSize == 0;
    }

    public boolean isFull() {
        return currentSize == capacity;
    }
}
```


**Uso:**

```Java
CircularQueue q = new CircularQueue(3);

q.enqueue(10);
q.enqueue(20);
System.out.println(q.dequeue()); // 10

q.enqueue(30);
q.enqueue(40);

System.out.println(q.dequeue()); // 20
System.out.println(q.dequeue()); // 30
System.out.println(q.isEmpty()); // false
System.out.println(q.dequeue()); // 40
System.out.println(q.isEmpty()); // true
```


---

### 4.4 Ejemplo: cola con `LinkedList` en Java

```Java
import java.util.LinkedList;
import java.util.Queue;

Queue<String> cola = new LinkedList<>();

cola.add("Juan");      // enqueue
cola.add("Ana");

System.out.println(cola.peek());   // "Juan"
System.out.println(cola.remove()); // "Juan"
System.out.println(cola.remove()); // "Ana"
System.out.println(cola.isEmpty()); // true
```


(Alternativas: `offer()` / `poll()` para evitar excepciones y devolver `false`/`null`.)

---

### 4.5 Complejidad

Con **lista enlazada** (`head` + `tail`):

- `enqueue`: $O(1)$.
    
- `dequeue`: $O(1)$.
    
- `peek`: $O(1)$.
    

Con **array circular**:

- `enqueue`: $O(1)$.
    
- `dequeue`: $O(1)$.
    
- `peek`: $O(1)$.
    

Con una implementación ingenua de array **sin** circularidad y haciendo `shift` al hacer `dequeue`, cada `dequeue` sería $O(n)$ y es mala idea.

Espacio: $O(n)$.

---

### 4.6 Mini resumen (chuleta mental)

- **Queue = FIFO**:
    
    - Primero en entrar, primero en salir.
        
    - Entra por `rear`, sale por `front`.
        
- **Operaciones**:
    
    - `enqueue`, `dequeue`, `peek`, `isEmpty`.
        
    - Todo $O(1)$ con lista enlazada o array circular.
        
- **Implementaciones**:
    
    - Linked list con `head`/`tail`.
        
    - Array circular (`(index + 1) % capacity`).
        
    - En Java: `Queue<E>` con `LinkedList` o `ArrayDeque`.
        
- **Errores típicos**:
    
    - Implementar cola con `ArrayList.remove(0)` (cada remove es $O(n)$).
        
    - No distinguir bien vacío vs lleno en buffer circular.
        
    - Underflow: `dequeue` en cola vacía.
        
- **Usos**:
    
    - BFS.
        
    - Buffers de mensajes (productor-consumidor).
        
    - Colas de impresión / jobs.
        

---

## 5. Colas de prioridad (priority queues)

### 5.1 Idea intuitiva

Una **cola de prioridad (priority queue)** es una cola donde cada elemento lleva una **prioridad**, y:

> Siempre sale primero el elemento con **mayor prioridad**,  
> no necesariamente el que llegó antes.

Ejemplos:

- Urgencias en un hospital: el caso más grave se atiende antes.
    
- Planificación de tareas: jobs más importantes o con deadline cercano se ejecutan antes.
    
- Algoritmo de Dijkstra: siempre procesas el vértice con menor distancia provisional (cola de prioridad de mínimos).
    

Si dos elementos tienen la misma prioridad, normalmente se respeta el orden de llegada (FIFO entre iguales), aunque en implementaciones típicas con _heap_ esto no siempre está garantizado automáticamente.

---

### 5.2 Definición formal

TAD **PriorityQueue**:

- `insert(x, p)` o simplemente `insert(x)` donde `x` tiene prioridad `p`.
    
- `extractMax()` / `extractMin()`:
    
    - Devuelve y elimina el elemento con **máxima** (o mínima) prioridad.
        
- `peekMax()` / `peekMin()`:
    
    - Devuelve el elemento de máxima prioridad sin eliminarlo.
        
- `isEmpty()`, `size()`, etc.
    

Implementaciones posibles:

- **Array desordenado**:
    
    - `insert`: $O(1)$.
        
    - `extractMax`: buscar máximo → $O(n)$.
        
- **Lista ordenada**:
    
    - `insert`: encontrar hueco → $O(n)$.
        
    - `extractMax`: sacar primero → $O(1)$.
        
- **Árbol balanceado (BST)**:
    
    - `insert`, `extractMax`: $O(log n)$.
        
- **Heap binario (binary heap)**:
    
    - `insert`, `extractMax`: $O(log n)$.
        
    - `peekMax`: $O(1)$.  
        → Es la implementación más común.
        

Por defecto, en muchas librerías estándar se usa un **min-heap** (sale el mínimo primero). Para un max-heap se invierte el comparador.

---

### 5.3 Heap binario (visión rápida)

Un **binary heap (max-heap)** es:

- Un árbol binario **completo** (se rellena por niveles de izquierda a derecha).
    
- Con la **propiedad de heap**:
    
    - Cada nodo es **mayor o igual** que sus hijos.
        

El máximo está **siempre en la raíz**.

Se representa muy fácil en un **array**:

- Raíz en índice `0`.
    
- Hijos de índice $i$: índices $2 * i + 1$ y $2 * i + 2$.
    
- Padre de índice $i$ (para $i > 0$): índice `floor((i - 1) / 2)`.
    

Operaciones típicas:

- `insert(x)`:
    
    1. Insertas `x` al final del array (como nueva hoja).
        
    2. Haces _bubble-up_ (subir) mientras `x` sea mayor que su padre.
        
    3. Coste peor caso: $O(log n)$.
        
- `extractMax()`:
    
    1. Guardas la raíz (máximo).
        
    2. Mueves el último elemento del array a la raíz.
        
    3. Haces _bubble-down_ (bajar) comparando con hijos y bajando hasta restaurar la propiedad de heap.
        
    4. Coste peor caso: $O(log n)$.
        
- `peekMax()`:
    
    - Devuelves `heap[0]` → coste $O(1)$.
        

---

### 5.4 Ejemplo en Java con `PriorityQueue`

En Java, `PriorityQueue<E>` es un **min-heap** por defecto (el menor sale primero). Para una cola de prioridad de **máximos** podemos usar un comparador.

```Java
import java.util.PriorityQueue;
import java.util.Comparator;

class Task {
    String name;
    int priority;

    public Task(String n, int p) {
        name = n;
        priority = p;
    }

    @Override
    public String toString() {
        return name + "(pri=" + priority + ")";
    }
}

PriorityQueue<Task> pq =
        new PriorityQueue<>(Comparator.comparingInt(t -> -t.priority));
// prioridades más altas salen primero

pq.add(new Task("TareaA", 3));
pq.add(new Task("TareaB", 5));
pq.add(new Task("TareaC", 1));

System.out.println(pq.peek());    // TareaB(pri=5)

while (!pq.isEmpty()) {
    System.out.println(pq.poll());
}
```


Salida esperada:

```
TareaB(pri=5)
TareaB(pri=5)
TareaA(pri=3)
TareaC(pri=1)
```


(La primera línea es del `peek`, las demás de los `poll`.)

---

### 5.5 Inserción en heap binario (idea de código)

```Java
import java.util.ArrayList;
import java.util.List;

class MaxHeap {
    private List<Integer> heap = new ArrayList<>();

    public void insert(int val) {
        heap.add(val);             // 1. añadir al final
        int i = heap.size() - 1;   // índice del nuevo

        // 2. bubble-up
        while (i > 0) {
            int parent = (i - 1) / 2;
            if (heap.get(parent) >= heap.get(i)) break;

            // swap
            int temp = heap.get(parent);
            heap.set(parent, heap.get(i));
            heap.set(i, temp);

            i = parent; // subir
        }
    }

    public int extractMax() throws Exception {
        if (heap.isEmpty()) {
            throw new Exception("Empty heap");
        }

        int max = heap.get(0);
        int last = heap.remove(heap.size() - 1);

        if (!heap.isEmpty()) {
            heap.set(0, last);
            bubbleDown(0);
        }

        return max;
    }

    private void bubbleDown(int i) {
        while (true) {
            int left = 2 * i + 1;
            int right = 2 * i + 2;
            int largest = i;

            if (left < heap.size() && heap.get(left) > heap.get(largest)) {
                largest = left;
            }
            if (right < heap.size() && heap.get(right) > heap.get(largest)) {
                largest = right;
            }
            if (largest == i) break;

            int temp = heap.get(i);
            heap.set(i, heap.get(largest));
            heap.set(largest, temp);

            i = largest;
        }
    }
}
```


No necesitas esto para exámenes de nivel medio, pero te enseña cómo funcionan de verdad las `PriorityQueue`.

---

### 5.6 Complejidad

Con implementación por **binary heap**:

- `insert`: $O(log n)$.
    
- `extractMax` / `extractMin`: $O(log n)$.
    
- `peek`: $O(1)$.
    
- `build-heap` desde un array de $n$ elementos: $O(n)$.
    

Otras opciones:

- Array desordenado:
    
    - `insert`: $O(1)$.
        
    - `extractMax`: $O(n)$.
        
- Lista ordenada:
    
    - `insert`: $O(n)$.
        
    - `extractMax`: $O(1)$.
        

El heap es un buen equilibrio: $O(log n)$ en inserción y extracción.

**Orden interno vs orden de salida:**

- La cola de prioridad no mantiene los elementos completamente ordenados en memoria.
    
- Solo garantiza que el próximo `extractMax`/`poll` devuelve el de **mayor prioridad**.
    
- Si extraes todos los elementos uno a uno, obtienes la secuencia ordenada por prioridad.
    

**Prioridades iguales:**

- El TAD conceptual suele asumir que a igual prioridad se podría respetar el orden de llegada.
    
- Un heap binario típico **no es estable**: el orden de elementos con prioridad igual puede depender de la estructura interna.
    
- Si quieres estabilidad, puedes usar un par `(priority, timestamp)` y definir el comparador como:
    
    - Primero por prioridad.
        
    - Luego por `timestamp` (menor timestamp = llegó antes).
        

---

### 5.7 Mini resumen (chuleta mental)

- **Cola de prioridad (priority queue)**:
    
    - Siempre sale primero el elemento con prioridad más alta (o más baja, según definición).
        
    - No respeta estrictamente FIFO, solo respeta las prioridades.
        
- **Operaciones**:
    
    - `insert(x, p)`, `extractMax()` / `extractMin()`, `peek()`, `isEmpty()`.
        
    - En heap: `insert` y `extract` en $O(log n)$, `peek` en $O(1)$.
        
- **Implementación típica**:
    
    - **Binary heap (montículo binario)**:
        
        - Árbol binario completo con propiedad de heap.
            
        - Representado por array.
            
        - `insert`: $O(log n)$ (bubble-up).
            
        - `extractMax`: $O(log n)$ (bubble-down).
            
        - `peekMax`: $O(1)$.
            
- **Ventajas**:
    
    - Mucho más eficiente que lista ordenada o desordenada cuando hay muchas operaciones mixtas de inserción y extracción.
        
    - Fundamental en algoritmos de grafos (Dijkstra, Prim), planificación de tareas, simulaciones de eventos, etc.
        
- **Desventajas**:
    
    - No es fácil eliminar un elemento arbitrario que no sea el tope (normalmente $O(n)$ si lo buscas).
        
    - No es estable si no se controla el desempate.
        
- **Errores típicos**:
    
    - Pensar que `PriorityQueue` de Java devuelve el **máximo** por defecto (devuelve el mínimo).
        
    - Esperar que iterar por la `PriorityQueue` devuelva elementos en orden de prioridad (no es así; hay que ir sacándolos con `poll()`).
        
    - No manejar el caso de heap vacío (hacer `poll`/`peek` sin comprobar).